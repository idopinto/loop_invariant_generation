[
    {
        "client": "together",
        "model_path_or_name": "openai/gpt-oss-20b",
        "sampling_params": {
            "temperature": 0.0,
            "max_tokens": 2048,
            "reasoning_effort": "low",
            "n": 1
        }
    },
    {
        "client": "together",
        "model_path_or_name": "openai/gpt-oss-120b",
        "sampling_params": {
            "temperature": 0.0,
            "max_tokens": 2048,
            "reasoning_effort": "low",
            "n": 1
        }
    },
    {
        "client": "together",
        "model_path_or_name": "openai/gpt-oss-20b",
        "sampling_params": {
            "temperature": 0.0,
            "max_tokens": 8192,
            "reasoning_effort": "medium",
            "n": 1
        }
    },
    {
        "client": "together",
        "model_path_or_name": "openai/gpt-oss-120b",
        "sampling_params": {
            "temperature": 0.0,
            "max_tokens": 8192,
            "reasoning_effort": "medium",
            "n": 1
        }
    },
    {
        "client": "together",
        "model_path_or_name": "openai/gpt-oss-20b",
        "sampling_params": {
            "temperature": 0.0,
            "max_tokens": 32768,
            "reasoning_effort": "high",
            "n": 1
        }
    },
    {
        "client": "together",
        "model_path_or_name": "openai/gpt-oss-120b",
        "sampling_params": {
            "temperature": 0.0,
            "max_tokens": 32768,
            "reasoning_effort": "high",
            "n": 1
        }
    }
]